{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the Data\n",
    "\n",
    "In this step, we will load the datasets required for fraud detection analysis. We have two datasets:\n",
    "1. **Fraud_Data.csv**: Contains the transaction information, including user details and whether the transaction is fraudulent.\n",
    "2. **IpAddress_to_Country.csv**: Maps IP address ranges to countries, which will help us enhance the fraud detection by identifying geographical locations of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class  \n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0  \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  \n",
       "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0  \n",
       "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "fraud_data = pd.read_csv('../Data/Raw/Fraud_Data.csv')\n",
    "ip_data = pd.read_csv('../Data/Raw/IpAddress_to_Country.csv')\n",
    "\n",
    "# Display first few rows of Fraud Data\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower_bound_ip_address</th>\n",
       "      <th>upper_bound_ip_address</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16777216.0</td>\n",
       "      <td>16777471</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16777472.0</td>\n",
       "      <td>16777727</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16777728.0</td>\n",
       "      <td>16778239</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16778240.0</td>\n",
       "      <td>16779263</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16779264.0</td>\n",
       "      <td>16781311</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lower_bound_ip_address  upper_bound_ip_address    country\n",
       "0              16777216.0                16777471  Australia\n",
       "1              16777472.0                16777727      China\n",
       "2              16777728.0                16778239      China\n",
       "3              16778240.0                16779263  Australia\n",
       "4              16779264.0                16781311      China"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows of Ip Data\n",
    "ip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning\n",
    "\n",
    "Data cleaning is a crucial step to ensure that our dataset is free from errors and inconsistencies. In this step, we will:\n",
    "- Handle missing values by removing or imputing them.\n",
    "- Remove any duplicate rows to avoid biased analysis.\n",
    "- Correct data types for certain columns, such as date-time and IP address conversion to integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           0\n",
       "signup_time       0\n",
       "purchase_time     0\n",
       "purchase_value    0\n",
       "device_id         0\n",
       "source            0\n",
       "browser           0\n",
       "sex               0\n",
       "age               0\n",
       "ip_address        0\n",
       "class             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "fraud_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lower_bound_ip_address    0\n",
       "upper_bound_ip_address    0\n",
       "country                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "ip_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "fraud_data = fraud_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "ip_data = ip_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop missing values (if any)\n",
    "fraud_data = fraud_data.dropna()\n",
    "\n",
    "# Correct data types\n",
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "fraud_data['ip_address'] = fraud_data['ip_address'].astype('int')\n",
    "\n",
    "# Display cleaned data information\n",
    "fraud_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA helps us understand the underlying patterns in the data. Here, we will:\n",
    "- Conduct **Univariate Analysis** to explore individual variables.\n",
    "- Perform **Bivariate Analysis** to explore relationships between features, especially how they correlate with fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Univariate analysis: Age distribution\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(fraud_data['age'], bins=20, kde=True)\n",
    "plt.title('Distribution of User Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Bivariate analysis: Purchase value vs. fraud status\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='class', y='purchase_value', data=fraud_data)\n",
    "plt.title('Purchase Value by Fraud Status')\n",
    "plt.xlabel('Fraud Status (0 = Non-fraudulent, 1 = Fraudulent)')\n",
    "plt.ylabel('Purchase Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Geolocation Analysis\n",
    "\n",
    "By merging the IP address data, we can incorporate geographical information into our fraud detection model. First, we convert IP addresses into an integer format and then merge the `fraud_data` with `ip_data` to add country information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert IP address to integer range for merging\n",
    "fraud_data = fraud_data.merge(ip_data, how='left', left_on='ip_address', right_on='lower_bound_ip_address')\n",
    "\n",
    "# Display the merged dataset\n",
    "fraud_data[['ip_address', 'country']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering\n",
    "\n",
    "In this step, we create new features that can provide more insight into fraudulent behavior:\n",
    "- **Time-based features**: Extract hour of the day and day of the week from `purchase_time`.\n",
    "- **Transaction count**: Count the number of transactions per user.\n",
    "- **Transaction velocity**: Calculate the time difference between signup and purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "fraud_data['transaction_hour'] = fraud_data['purchase_time'].dt.hour\n",
    "fraud_data['transaction_day'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "\n",
    "# Transaction count per user\n",
    "fraud_data['transaction_count'] = fraud_data.groupby('user_id')['purchase_time'].transform('count')\n",
    "\n",
    "# Transaction velocity (time between signup and purchase)\n",
    "fraud_data['time_to_purchase'] = (fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds()\n",
    "\n",
    "# Display updated dataframe with new features\n",
    "fraud_data[['transaction_hour', 'transaction_day', 'transaction_count', 'time_to_purchase']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Encoding Categorical Features and Scaling\n",
    "\n",
    "For machine learning models to work efficiently, categorical features need to be converted into numeric format using one-hot encoding. Also, numerical features should be scaled so that they are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# One-hot encoding categorical features\n",
    "categorical_features = ['source', 'browser', 'sex']\n",
    "fraud_data = pd.get_dummies(fraud_data, columns=categorical_features)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['purchase_value', 'age', 'transaction_count', 'time_to_purchase']\n",
    "fraud_data[numerical_features] = scaler.fit_transform(fraud_data[numerical_features])\n",
    "\n",
    "# Display final processed data\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save the Processed Data\n",
    "\n",
    "After completing data preprocessing, we will save the cleaned and processed data to a new CSV file, which will be used for model training in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned and processed data to a new file\n",
    "fraud_data.to_csv('../Data/Processed/cleaned_fraud_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
